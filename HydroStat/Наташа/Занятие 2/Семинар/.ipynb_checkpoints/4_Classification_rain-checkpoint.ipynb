{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn - библиотека машинного обучения на языке Python. В ней реализовано практически все необходимое для машинного обучения.\n",
    "\n",
    "+ разделение выборки на тестовую и обучающую\n",
    "+ основные метрики\n",
    "+ кроссвалидация\n",
    "+ линейная регрессия и ее модификация\n",
    "+ задачи классификации\n",
    "+ кластеризация\n",
    "+ различные методы работы с признаками\n",
    "\n",
    "Познакомимся с частью ее фишек сначала на тренировочном примере, а потом на примере прогнозирования ледового затора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **0. Импорт необходимых пакетов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# нам понадобится отрисовка графиков\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Загрузка данных**\n",
    "\n",
    "\n",
    "В качестве тренировочного датасета возьмем различные метеоданные Австралии и будем предсказывать, будет ли завтра дождь).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('weatherAUS.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какие у нас признаки, есть ли пропуски."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание принаков. https://www.kaggle.com/jsphyg/weather-dataset-rattle-package/data\n",
    "\n",
    "+ **Location** The common name of the location of the weather station\n",
    "+ **MinTemp** The minimum temperature in degrees celsius\n",
    "+ **MaxTemp** The maximum temperature in degrees celsius\n",
    "+ **Rainfall** The amount of rainfall recorded for the day in mm\n",
    "+ **Evaporation** The so-called Class A pan evaporation (mm) in the 24 hours to 9am\n",
    "+ **Sunshine** The number of hours of bright sunshine in the day.\n",
    "+ **WindGustDir** The direction of the strongest wind gust in the 24 hours to midnight\n",
    "+ **WindGustSpeed** The speed (km/h) of the strongest wind gust in the 24 hours to midnight\n",
    "+ **WindDir9am** Direction of the wind at 9am\n",
    "+ **WindDir3pm** Direction of the wind at 3pm\n",
    "+ **WindSpeed9am** Wind speed (km/hr) averaged over 10 minutes prior to 9am\n",
    "+ **WindSpeed3pm** Wind speed (km/hr) averaged over 10 minutes prior to 3pm\n",
    "+ **Humidity9am** Humidity (percent) at 9am\n",
    "+ **Humidity3pm** Humidity (percent) at 3pm\n",
    "+ **Pressure9am** Atmospheric pressure (hpa) reduced to mean sea level at 9am\n",
    "+ **Pressure3pm** Atmospheric pressure (hpa) reduced to mean sea level at 3pm\n",
    "+ **Cloud9am** Fraction of sky obscured by cloud at 9am. This is measured in \"oktas\", which are a unit of eigths. It records how many eigths of the sky are obscured by cloud. A 0 measure indicates completely clear sky whilst an 8 indicates that it is completely overcast.\n",
    "+ **Cloud3pm** Fraction of sky obscured by cloud (in \"oktas\": eighths) at 3pm. See Cload9am for a description of the values\n",
    "+ **Temp9am** Temperature (degrees C) at 9am\n",
    "+ **Temp3pm** Temperature (degrees C) at 3pm\n",
    "+ **RainToday** Boolean: 1 if precipitation (mm) in the 24 hours to 9am exceeds 1mm, otherwise 0\n",
    "+ **RISK_MM** The amount of next day rain in mm. Used to create response variable RainTomorrow. A kind of measure of the \"risk\".\n",
    "+ **RainTomorrow** The target variable. Did it rain tomorrow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, на сбалансированность выборки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.RainTomorrow.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что выборка не очень сбалансированна, но это не слишком критично. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что будем делать с пропусками?**\n",
    "\n",
    "Первое, что мы сделаем - посчитаем, сколько у нас пропусков у каждого из признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Мы видим, что есть несколько признаков, у которых пропусков порядка половины. Тут ничего не поделаешь - придется удалять их**\n",
    "\n",
    "Плюс нам не нужны в качестве признаков дата, локация и значение осадков на следующий день (их можно будет успользовать как целевую переменную при предсказании количества осадков на следующий день)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(labels = ['Date','Location','Evaporation',\n",
    "                       'Sunshine','Cloud3pm','Cloud9am','RISK_MM'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выделим столбец с предсказаниями и таблицу с признаками**\n",
    "\n",
    "Видим, что прогноз на завтра и за сегодня имеют тип объекта, а нам хотелось бы число. 0 или 1. Перекодируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['RainTomorrow'] = data['RainTomorrow'].map({'Yes': 1, 'No': 0}) \n",
    "data['RainToday'] = data['RainToday'].map({'Yes': 1, 'No': 0}) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Остальных пропусков не очень много - безжалостно удаляем наблюдения с ними с помощью функции dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**У нас осталось три признака типа оbject. Что будем с ними делать?** \n",
    "\n",
    "Заменим каждый признак на несколько признаков с помощью функции get_dummies. Что она делает?\n",
    "\n",
    "Если признак принимает три значения, она создает три новых признака - флаги каждого из значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['WindGustDir','WindDir9am','WindDir3pm']\n",
    "\n",
    "data = pd.get_dummies(data,columns = categorical,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь создаем таблицу признаков и вектор целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['RainTomorrow']\n",
    "data.drop(['RainTomorrow'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Построим самые первые и простые модели**\n",
    "\n",
    "Данных очень много, поэтому попробуем работать только с 20% всех данных\n",
    "\n",
    "Выделим 70% выборки (X_train, y_train) под обучение и 30% будут тестовой выборкой (X_test, y_test) с помощью функции **train_test_split**. Тестовая выборка никак не будет участвовать в настройке параметров моделей, на ней мы в конце, после этой настройки, оценим качество полученной модели. \n",
    "\n",
    "Построим решающее дерево и метод 1 ближайшего соседа (параметры пока подбирать не будем), а так же сравним результаты со случайным и негативным классификатором (дождя нет). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим функцию разделения на тестовую и обучающую\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_learn, X_another, Y_learn, Y_another = train_test_split(data, y, test_size = 0.8, random_state = 42)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_learn, Y_learn, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "#Обучение модели - функция fit\n",
    "\n",
    "tree.fit(X_train, Y_train)\n",
    "neigh.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим качество построенных моделей.\n",
    "В качестве метрик посмотрим на accuracy, precision, recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получить предсказания обученной модели по новому набору данных - функция predict\n",
    "tree_pred = tree.predict(X_test)\n",
    "neigh_pred = neigh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Real accuracy', 1 - Y_test.sum()/len(Y_test))\n",
    "print('Tree', accuracy_score(Y_test, tree_pred))\n",
    "print('Neighboors',accuracy_score(Y_test, neigh_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что если мы просто запустим две простые модели, что качество уже будет лучше, чем если бы мы просто сказали, что дождя никогда не будет. Но у нас несбалансированная выбока"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, balanced_accuracy_score\n",
    "print('Decision Tree:')\n",
    "print('Accuracy', accuracy_score(Y_test, tree_pred))\n",
    "print('Balanced accuracy', balanced_accuracy_score(Y_test, tree_pred))\n",
    "print('Precision', precision_score(Y_test, tree_pred, pos_label=1))\n",
    "print('Recall', recall_score(Y_test, tree_pred))\n",
    "print('1 NN:')\n",
    "print('Accuracy', accuracy_score(Y_test, neigh_pred))\n",
    "print('Balanced accuracy', balanced_accuracy_score(Y_test, tree_pred))\n",
    "print('Precision', precision_score(Y_test, neigh_pred))\n",
    "print('Recall', recall_score(Y_test, neigh_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Настроим параметры модели**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дерево\n",
    "Настроим оптимальные параметры для нашего дерева. Будем оптимизировать максимальную глубину дерева и максимальное используемое число признаков при каждом разбиении.\n",
    "GridSearchCV - обход по сетке параметров. Для каждой уникальной пары значений параметров max_depth и max_features будет проведена 10-кратная кросс-валидация и выберется лучшее сочетание параметров.\n",
    "\n",
    "В качестве метрики будем использовать balanced accuracy. \n",
    "\n",
    "Названия метрик можно посмотреть тут https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tree_params = {\n",
    "    'max_depth': range(1,10),\n",
    "    'max_features': range(4,20)\n",
    "}\n",
    "kf = KFold(random_state = 42, shuffle = True, n_splits = 5)\n",
    "\n",
    "tree_grid = GridSearchCV(tree, tree_params, cv=kf, n_jobs=-1, scoring='balanced_accuracy')\n",
    "# смотрим, что у нас будет на нашей решетке на тренировочных данных\n",
    "tree_grid.fit(X_train, Y_train)\n",
    "\n",
    "print(tree_grid.best_params_, tree_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим нашу модель на этих параметрах и посмотрим качество модели на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_best = DecisionTreeClassifier(max_depth=4, max_features=10, random_state=42)\n",
    "\n",
    "tree_best.fit(X_train, Y_train)\n",
    "tree_best_pred = tree_best.predict(X_test)\n",
    "\n",
    "print('Decision Tree:')\n",
    "print('Accuracy', accuracy_score(Y_test, tree_best_pred))\n",
    "print('Balanced accuracy', balanced_accuracy_score(Y_test, tree_best_pred))\n",
    "print('Precision', precision_score(Y_test, tree_best_pred, pos_label=1))\n",
    "print('Recall', recall_score(Y_test, tree_best_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Y_test,tree_best_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замечание!\n",
    "\n",
    "На лекции обсуждалось, что метрические классификаторы очень чувствительны к масштабу признаков. Попробуем сначала признаки отмасштабировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "sc_X_train = scaler.fit_transform(X_train)\n",
    "sc_X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_sc = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "neigh_sc.fit(sc_X_train, Y_train)\n",
    "neigh_pred = neigh_sc.predict(sc_X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('1 NN:')\n",
    "print('Accuracy', accuracy_score(Y_test, neigh_pred))\n",
    "print('Balanced accuracy', balanced_accuracy_score(Y_test, neigh_pred))\n",
    "print('Precision', precision_score(Y_test, neigh_pred))\n",
    "print('Recall', recall_score(Y_test, neigh_pred))\n",
    "print(classification_report(Y_test,tree_best_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускать подбор параметров по всем признакам - смертельный номер. Компьютер просто умрет.\n",
    "\n",
    "Поэтому выберем 10 самых наилучших признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f = SelectKBest(f_classif, k=10)\n",
    "X_train_new = best_f.fit_transform(X_train, Y_train)\n",
    "X_test_new = best_f.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подберем для каждого масштабирования оптимальные параметры. Выберем наилучший вариант. Обучим модель и проверим ее качество на тренировочной выборке\n",
    "\n",
    "количество соседей от 1 до 15, веса - равномерные и расстояние, метрика - евклидова и минковского"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, MinMaxScaler\n",
    "\n",
    "scalers = [StandardScaler(), MaxAbsScaler(), MinMaxScaler()]\n",
    "\n",
    "for scaler in scalers:\n",
    "    #print(str(scaler))\n",
    "    sc_X_train = scaler.fit_transform(X_train_new)\n",
    "    \n",
    "    grid_params = {\n",
    "        'n_neighbors':  np.arange(1, 16, 2),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['minkowski', 'manhattan']\n",
    "    }\n",
    "    \n",
    "    KNN = KNeighborsClassifier()\n",
    "    kf = KFold(random_state = 42, shuffle = True, n_splits = 5)\n",
    "    grid = GridSearchCV(KNN, grid_params, cv = kf, scoring = 'balanced_accuracy')\n",
    "    grid.fit(sc_X_train, Y_train)\n",
    "    \n",
    "    print(scaler, grid.best_params_, grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "sc_X_train = scaler.fit_transform(X_train_new)\n",
    "sc_X_test = scaler.transform(X_test_new)\n",
    "\n",
    "KNN_best = KNeighborsClassifier(metric = 'minkowski', n_neighbors = 11, weights = 'uniform')\n",
    "\n",
    "KNN_best.fit(sc_X_train, Y_train)\n",
    "KNN_best_pred = KNN_best.predict(sc_X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best KNN:')\n",
    "print('Accuracy', accuracy_score(Y_test, KNN_best_pred))\n",
    "print('Balanced accuracy', balanced_accuracy_score(Y_test, KNN_best_pred))\n",
    "print('Precision', precision_score(Y_test, KNN_best_pred, pos_label=1))\n",
    "print('Recall', recall_score(Y_test, KNN_best_pred))\n",
    "print(classification_report(Y_test,tree_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy 0.7590023612750886\n",
    "Balanced accuracy 0.6261425801492546\n",
    "Precision 0.4323507180650038\n",
    "Recall 0.3933975240715268"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
